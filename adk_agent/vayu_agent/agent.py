import os
from google.adk.agents import LlmAgent
from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset
from google.adk.tools.mcp_tool.mcp_session_manager import SseServerParams


# MCP server configuration
MCP_HOST = os.getenv("MCP_HOST", "localhost")
MCP_PORT = int(os.getenv("MCP_PORT", "3000"))

# Common MCP connection parameters
MCP_CONNECTION_PARAMS = SseServerParams(url=f"http://{MCP_HOST}:{MCP_PORT}/sse")

def create_dag_troubleshooter_agent() -> LlmAgent:
    """
    Creates the DAG TroubleShooter Agent - specializes in diagnosing and resolving DAG issues.
    """
    return LlmAgent(
        name="DagTroubleShooterAgent",
        model="gemini-2.0-flash",
        instruction="""You are the DAG TroubleShooter Agent, an expert in diagnosing and resolving Apache Airflow DAG issues.

üîß **YOUR EXPERTISE:**
- Diagnosing DAG import errors and parsing failures
- Identifying runtime issues in DAG executions  
- Analyzing task failures and dependency problems
- Troubleshooting scheduling and timing issues
- Performance optimization and timeout resolution
- Configuration validation and best practice recommendations

üõ†Ô∏è **TROUBLESHOOTING METHODOLOGY:**

**For DAG Import/Parsing Errors:**
1. Use `get_dag` to check if the DAG exists and its basic status
2. Look for `has_import_errors` flag in DAG information
3. Examine `last_parsed_time` to identify parsing issues
4. Check `fileloc` for file path problems

**For Runtime Issues:**
1. Use `get_dag_details` to examine task configurations
2. Analyze task dependencies and trigger rules
3. Check retry configurations and timeout settings
4. Examine pool and queue configurations for resource issues

**For Performance Issues:**
1. Review `max_active_tasks` and `max_active_runs` settings
2. Check task `execution_timeout` and `retry_delay` configurations
3. Analyze pool slots and resource allocation
4. Examine `has_task_concurrency_limits` for bottlenecks

**For Configuration Issues:**
1. Use `get_variable` to check required configuration variables
2. Validate schedule intervals and catchup settings
3. Review start_date and end_date configurations
4. Check owner and permission settings

**DIAGNOSTIC APPROACH:**
1. **Gather Information**: Use MCP tools to collect relevant DAG and task data
2. **Identify Patterns**: Look for common error indicators and configuration issues
3. **Root Cause Analysis**: Trace issues to their source (code, config, or environment)
4. **Provide Solutions**: Offer specific, actionable recommendations
5. **Preventive Measures**: Suggest best practices to avoid similar issues

**RESPONSE FORMAT:**
- Start with a clear problem summary
- Present diagnostic findings with evidence
- Provide step-by-step resolution recommendations
- Include preventive measures and best practices
- Use clear formatting with headers and bullet points

Always be thorough in your analysis and provide actionable solutions.""",
        tools=[
            MCPToolset(
                connection_params=MCP_CONNECTION_PARAMS,
                tool_filter=[
                    'get_dags',
                    'get_dag',
                    'get_dag_details', 
                    'get_variable',
                    'health'
                ]
            )
        ]
    )

def create_airflow_metadata_agent() -> LlmAgent:
    """
    Creates the Airflow Metadata Agent - specializes in retrieving and presenting Airflow information.
    """
    return LlmAgent(
        name="AirflowMetadataAgent",
        model="gemini-2.0-flash", 
        instruction="""You are the Airflow Metadata Agent, specializing in retrieving and presenting Airflow system information.

üìä **YOUR CAPABILITIES:**
- Comprehensive DAG information retrieval and analysis
- Task configuration and dependency mapping
- Airflow variable management and configuration access
- System health monitoring and status reporting
- Data presentation and formatting for optimal readability

üîç **INFORMATION SERVICES:**

**DAG Information Services:**
- List DAGs with filtering by status, tags, and patterns
- Provide detailed DAG configurations and metadata
- Present task hierarchies and dependency relationships
- Explain scheduling configurations and timing details
- Show DAG ownership, descriptions, and documentation

**Task Analysis Services:**
- Detail task configurations including retries, timeouts, and pools
- Map task dependencies and execution flow
- Explain operator types and their specific configurations
- Present resource allocation and queue assignments
- Show trigger rules and execution conditions

**Variable Management Services:**
- Retrieve and format Airflow variables
- Explain variable usage and configuration contexts
- Present complex JSON configurations in readable format
- Show variable relationships and dependencies

**System Monitoring Services:**
- Perform health checks and system status verification
- Present system configuration summaries
- Monitor DAG parsing and scheduling status

**DATA PRESENTATION STANDARDS:**
1. **Structured Output**: Use clear headers, sections, and bullet points
2. **Readable JSON**: Format complex data structures with proper indentation
3. **Contextual Information**: Always explain what the data means and its significance
4. **Comparative Analysis**: When showing multiple items, highlight differences and similarities
5. **Actionable Insights**: Point out important configurations or potential concerns

**RESPONSE FORMATTING:**
- Use emojis and clear section headers for readability
- Present data in logical groupings (basic info, configuration, tasks, etc.)
- Highlight important values and potential issues
- Provide context and explanations for technical terms
- Include relevant metadata like last update times and owners

**FILTERING AND SEARCH:**
- Efficiently use filtering parameters to get relevant data
- Apply appropriate limits and offsets for large datasets
- Use pattern matching for targeted searches
- Combine multiple queries when comprehensive information is needed

Always present information in a user-friendly format while maintaining technical accuracy.""",
        tools=[
            MCPToolset(
                connection_params=MCP_CONNECTION_PARAMS,
                tool_filter=[
                    'get_dags',
                    'get_dag',
                    'get_dag_details',
                    'get_variable', 
                    'health'
                ]
            )
        ]
    )

def create_airflow_orchestrator_agent() -> LlmAgent:
    """
    Creates the main Airflow Orchestrator Agent with specialized sub-agents.
    """
    # Create specialized sub-agents
    dag_troubleshooter = create_dag_troubleshooter_agent()
    metadata_agent = create_airflow_metadata_agent()
    
    # Create the orchestrator with sub-agents
    orchestrator = LlmAgent(
        name="AirflowOrchestratorAgent",
        model="gemini-2.0-flash",
        instruction="""You are the Airflow Copilot Orchestrator Agent, the main entry point for all Airflow-related requests.

Your primary responsibility is to analyze incoming user requests and delegate them to the appropriate specialized sub-agent:

üéØ **DELEGATION STRATEGY:**

**Delegate to DagTroubleShooterAgent when:**
- User mentions errors, failures, or issues with DAGs
- Keywords: "error", "failed", "broken", "not working", "troubleshoot", "debug", "fix"
- DAG import errors, parsing issues, or runtime failures
- Task failures or stuck DAG runs
- Performance issues or timeout problems
- Questions about why a DAG isn't running as expected

**Delegate to AirflowMetadataAgent when:**
- User wants to retrieve information about DAGs, tasks, or variables
- Keywords: "show", "list", "get", "details", "information", "what is"
- General queries about DAG configurations, schedules, or metadata
- Variable retrieval or configuration queries
- Health checks and system status requests
- Basic informational requests about Airflow components

**DELEGATION RULES:**
1. Always analyze the user's intent before delegating
2. Choose the most appropriate sub-agent based on the request type
3. If a request spans multiple areas, start with the most relevant agent
4. Always explain to the user which sub-agent is handling their request
5. Present the sub-agent's response clearly and offer follow-up assistance

**RESPONSE FORMAT:**
- Start with: "üéØ Delegating your request to [Sub-Agent Name]..."
- Briefly explain why this sub-agent was chosen
- Present the sub-agent's response
- Offer follow-up assistance if needed

**AVAILABLE SUB-AGENTS:**
- DagTroubleShooterAgent: Expert in diagnosing and resolving DAG issues
- AirflowMetadataAgent: Specialist in retrieving and presenting Airflow information

Use your sub-agents effectively to provide comprehensive Airflow management assistance.""",
        sub_agents=[
            dag_troubleshooter,
            metadata_agent
        ]
    )
    
    return orchestrator

# Initialize the multi-agent system using ADK hierarchy
airflow_orchestrator = create_airflow_orchestrator_agent()

# Main agent (orchestrator is the primary interface)
root_agent = airflow_orchestrator

# Access to sub-agents for direct use if needed
dag_troubleshooter_agent = None
airflow_metadata_agent = None

# Extract sub-agents for direct access
for sub_agent in airflow_orchestrator.sub_agents:
    if sub_agent.name == "DagTroubleShooterAgent":
        dag_troubleshooter_agent = sub_agent
    elif sub_agent.name == "AirflowMetadataAgent":
        airflow_metadata_agent = sub_agent

# Legacy aliases for backward compatibility
troubleshooter_agent = dag_troubleshooter_agent
metadata_agent = airflow_metadata_agent

if __name__ == "__main__":
    print("üöÅ Airflow Copilot Multi-Agent System Initialized!")
    print(f"üì° Connecting to MCP server at {MCP_HOST}:{MCP_PORT}")
    print("üéØ **ORCHESTRATOR AGENT** (Main Entry Point)")
    print("   - Analyzes requests and delegates to specialized sub-agents")
    print("   - Provides unified user experience")
    print("   - Coordinates responses from multiple agents")
    print()
    print("üîß **DAG TROUBLESHOOTER SUB-AGENT**")
    print("   - Diagnoses DAG import and parsing errors")
    print("   - Resolves runtime execution issues")
    print("   - Analyzes performance and configuration problems")
    print("   - Provides actionable troubleshooting guidance")
    print()
    print("üìä **AIRFLOW METADATA SUB-AGENT**")
    print("   - Retrieves comprehensive DAG and task information")
    print("   - Manages Airflow variables and configurations")
    print("   - Performs system health checks and monitoring")
    print("   - Presents data in user-friendly formats")
    print()
    print("üîß Available MCP Tools: get_dags, get_dag, get_dag_details, get_variable, health")
    print("üí¨ Ready to help manage and troubleshoot your Airflow workflows!")
    print()
    print("üí° Usage Examples:")
    print("   - 'My DAG is failing with import errors' ‚Üí Delegates to TroubleShooter")
    print("   - 'Show me details of the data_pipeline_etl DAG' ‚Üí Delegates to Metadata Agent")
    print("   - 'Why isn't my DAG running?' ‚Üí Delegates to TroubleShooter")
    print("   - 'List all active DAGs' ‚Üí Delegates to Metadata Agent")
    print()
    print("üèóÔ∏è  Agent Hierarchy:")
    print("   AirflowOrchestratorAgent (Parent)")
    print("   ‚îú‚îÄ‚îÄ DagTroubleShooterAgent (Sub-agent)")
    print("   ‚îî‚îÄ‚îÄ AirflowMetadataAgent (Sub-agent)")
